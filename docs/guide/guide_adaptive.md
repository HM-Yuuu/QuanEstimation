# **Adaptive measurement schemes**
In QuanEstimation, the Hamiltonian of the adaptive system should be written as
$H(\textbf{x}+\textbf{u})$ with $\textbf{x}$ the unknown parameters and $\textbf{u}$ 
the tunable parameters. The tunable parameters $\textbf{u}$ are used to let the 
Hamiltonian work at the optimal point $\textbf{x}_{\mathrm{opt}}$. For this scenario,
the adaptive estimation can be excuted through
``` py
apt = adaptive(x, p, rho0, savefile=False, max_episode=1000, eps=1e-8)
apt.dynamics(tspan, H, dH, Hc=[], ctrl=[], decay=[])               
apt.CFIM(M=[], W=[]) 
```
where `x` is a list of arrays representing the regime of the parameters for the integral, 
`p` is an array representing the prior distribution, it is multidimensional for multiparameter
estimation.`rho` is a density matrix of the probe state.  The number of iterations can be 
set via `max_episode` with the default value 1000. `eps` represents the machine epsilon which 
defaults to $10^{-8}$. Three files "pout.npy", "xout.npy", and "y.npy" will be generated 
including the posterior distributions, the estimated values, and the experimental results. 
If `savefile=True`, these files will be generated during the training and "pout.npy" will save
all the posterior distributions, otherwise, the posterior distribution in the final iteration 
will be saved at the end of the program. 

If the dynamics of the system can be described by the master equation, then the dynamics data 
`tspan`, `H`, and `dH` shoule be input, `tspan` is the time length for the evolution, `H` and 
`dH` are multidimensional lists representing the Hamiltonian and its derivatives on the unknown 
parameters to be estimated, they can be generated via
``` py
H, dH = AdaptiveInput(x, func, dfunc, channel="dynamics")
```
Here `func` and `dfunc` are the function defined by the users which return `H` and `dH`, 
respectively. Futhermore, for the systems with noise and controls, the variables `decay`, 
`Hc`, and `ctrl` should be input. Here `Hc` and `ctrl` are two lists representing the control 
Hamiltonians and the corresponding control coefficients. `decay` contains decay operators 
$(\Gamma_1, \Gamma_2, \cdots)$ and the corresponding decay rates $(\gamma_1, \gamma_2, \cdots)$
with the input rule decay=[[$\Gamma_1$, $\gamma_1$], [$\Gamma_2$, $\gamma_2$],...].  

The objective function for adaptive estimation are CFI and $\mathrm{Tr}(W\mathcal{I}^
{-1})$ with $I$ the CFIM. `W` is the weight matrix which defaults to the identity matrix.

If the parameterization is implemented with the Kraus operators, the codes become
``` py
apt = adaptive(x, p, rho0, savefile=False, max_episode=1000, eps=1e-8)
apt.kraus(K, dK)               
apt.CFIM(M=[], W=[]) 
```
and 
``` py
K, dK = AdaptiveInput(x, func, dfunc, channel="kraus")
```
where `K` and `dK` are the Kraus operators and its derivatives on the unknown parameters.

---
Berry et al. [[1,2]](#Berry2000) introduced a famous adaptive scheme in phase estimation. The 
phase for the $(n+1)$th round is updated via $\Phi_{n+1}=\Phi_{n}-(-1)^{y^{(n)}}\Delta
\Phi_{n+1}$ with $y^{(n)}$ the experimental result in the $n$th round and $\Delta\Phi_{n+1}$ 
the phase difference generated by the proper algorithms. This adaptive scheme can be performed
in QuanEstimation by
``` py
apt = adaptMZI(x, p, rho0)
apt.general()
apt.online(output="phi")
```
Here `x`, `p`, and `rho0` are the same with `adaptive`. The output can be set through 
`output="phi"` (default) and `output="dphi"` representing the phase and phase difference, 
respectively. Online and offline strategies are both available in the package and the code for 
calling offline stratege becomes `apt.offline(method="DE", **kwargs)` or 
`apt.offline(method="PSO", **kwargs)`. If `method="DE"`, `**kwargs` is
``` py
kwargs = {"popsize":10, "DeltaPhi0":[], "max_episode":1000, "c":1.0, 
          "cr":0.5, "seed":1234}
```

| $~~~~~~~~~~$**kwargs$~~~~~~~~~~$ | $~~~~$default values$~~~~$ |
| :----------:                     | :----------:               |
| "popsize"                        | 10                         |
| "DeltaPhi0"                      | [ ]                        |
| "max_episode"                    | 1000                       |
| "c"                              | 1.0                        |
| "cr"                             | 0.5                        |
| "seed"                           | 1234                       |

`DeltaPhi0` represents the initial guesses of phase difference. `popsize` and `max_episode` 
are the number of populations and training episodes. `c` and `cr` are DE parameters 
representing the mutation and crossover constants, `seed` is the random seed which can
ensure the reproducibility of results.

If `method="PSO"`, `**kwargs` becomes
``` py
kwargs = {"particle_num":10, "DeltaPhi0":[], "max_episode":[1000,100], 
          "c0":1.0, "c1":2.0, "c2":2.0, "seed":1234}
```

| $~~~~~~~~~~$**kwargs$~~~~~~~~~~$ | $~~~~$default values$~~~~$ |
| :----------:                     | :----------:               |
| "particle_num"                   | 10                         |
| "DeltaPhi0"                          | [ ]                        |
| "max_episode"                    | [1000,100]                 |
| "c0"                             | 1.0                        |
| "c1"                             | 2.0                        |
| "c2"                             | 2.0                        |
| "seed"                           | 1234                       |

Here `particle_num` is the number of particles, `max_episode` accepts both integer and 
array with two elements. If it is an integer, for example `max_episode=1000`, it means the 
program will continuously run 1000 episodes. However, if it is an array, for example 
`max_episode=[1000,100]`, the program will run 1000 episodes in total but replace the data 
of all the particles with global best every 100 episodes. `c0`, `c1`, and `c2` are the PSO 
parameters representing the inertia weight, cognitive learning factor and social 
learning factor, respectively. 

---

## **Bibliography**
<a id="Berry2000">[1]</a>
D. W. Berry and H. M. Wiseman, 
Optimal States and Almost Optimal Adaptive Measurements for Quantum Interferometry, 
[Phys. Rev. Lett. **85**, 5098 (2000).](https://doi.org/10.1103/PhysRevLett.85.5098)

<a id="Berry2001">[2]</a>
D. W. Berry, H. M. Wiseman, and J. K. Breslin, 
Optimal input states and feedback for interferometric phase estimation, 
[Phys. Rev. A **63**, 053804 (2001).](https://doi.org/10.1103/PhysRevA.63.053804)
